{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain Runnables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnable Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "from langchain.schema.runnable import RunnableSequence\n",
    "from langchain_groq import ChatGroq\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "## load the GROQ API Key\n",
    "os.environ['GROQ_API_KEY']=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "model=ChatGroq(groq_api_key=groq_api_key,model_name=\"gemma2-9b-it\")\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = PromptTemplate(\n",
    "    template='Write a joke about {topic}',\n",
    "    input_variables=['topic']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = PromptTemplate(\n",
    "    template='Explain the following joke - {text}',\n",
    "    input_variables=['text']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This joke plays on the common trope of the \"chicken crossing the road\" joke.  \n",
      "\n",
      "* **The Setup:** The classic setup is \"Why did the chicken cross the road?\"  The punchline usually involves something silly or unexpected about the chicken's motivation.\n",
      "\n",
      "* **The Twist:** This joke subverts the expectation by replacing the chicken with an AI.  \n",
      "\n",
      "* **The Punchline:** The punchline \"Because it was programmed to!\" highlights the deterministic nature of AI.  AIs don't have free will or make decisions based on whims like a chicken might. Their actions are determined by their programming.\n",
      "\n",
      "\n",
      "The combination of the familiar setup and the unexpected twist creates humor.  üêîü§ñ  \n",
      "\n",
      "Let's hear another one! üòÑ  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chain = RunnableSequence(prompt1, model, parser, prompt2, model, parser)\n",
    "\n",
    "print(chain.invoke({'topic':'AI'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnable Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = PromptTemplate(\n",
    "    template='Generate a tweet about {topic}',\n",
    "    input_variables=['topic']\n",
    ")\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    template='Generate a Linkedin post about {topic}',\n",
    "    input_variables=['topic']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_chain = RunnableParallel({\n",
    "    'tweet': RunnableSequence(prompt1, model, parser),\n",
    "    'linkedin': RunnableSequence(prompt2, model, parser)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tweet': 'AI is changing the world faster than ever! ü§Ø From chatbots to self-driving cars, the possibilities are endless. What are you most excited to see AI achieve next? #AI #Innovation #FutureTech üöÄ \\n\\n', 'linkedin': \"##  Is AI a Friend or Foe? ü§î\\n\\nArtificial intelligence is rapidly changing the world around us, but what does it mean for the future of work? \\n\\nWhile AI presents incredible opportunities for innovation and efficiency, it also raises concerns about job displacement and ethical considerations. \\n\\n**Here are some key things to consider:**\\n\\n* **Embrace lifelong learning:**  AI will automate many tasks, so it's crucial to develop skills that complement and enhance AI capabilities, like critical thinking, creativity, and emotional intelligence.\\n* **Focus on human-centric skills:**  AI excels at processing data, but it lacks empathy and emotional intelligence.  Cultivating these skills will be essential for building human connections and navigating complex social situations.\\n* **Promote ethical development and use of AI:**  As AI becomes more powerful, it's vital to ensure it is developed and used responsibly, with fairness, transparency, and accountability at its core.\\n\\n**What are your thoughts on the impact of AI? Share your perspectives in the comments below!** \\n\\n#AI #ArtificialIntelligence #FutureOfWork #Innovation #Ethics #Technology #LifelongLearning #HumanSkills #Discussion  \\n\\n\\n\\n\"}\n"
     ]
    }
   ],
   "source": [
    "result = parallel_chain.invoke({'topic':'AI'})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: \n",
      " AI is changing the world faster than ever! ü§Ø From chatbots to self-driving cars, the possibilities are endless. What are you most excited to see AI achieve next? #AI #Innovation #FutureTech üöÄ \n",
      "\n",
      "\n",
      "Linkedin: \n",
      " ##  Is AI a Friend or Foe? ü§î\n",
      "\n",
      "Artificial intelligence is rapidly changing the world around us, but what does it mean for the future of work? \n",
      "\n",
      "While AI presents incredible opportunities for innovation and efficiency, it also raises concerns about job displacement and ethical considerations. \n",
      "\n",
      "**Here are some key things to consider:**\n",
      "\n",
      "* **Embrace lifelong learning:**  AI will automate many tasks, so it's crucial to develop skills that complement and enhance AI capabilities, like critical thinking, creativity, and emotional intelligence.\n",
      "* **Focus on human-centric skills:**  AI excels at processing data, but it lacks empathy and emotional intelligence.  Cultivating these skills will be essential for building human connections and navigating complex social situations.\n",
      "* **Promote ethical development and use of AI:**  As AI becomes more powerful, it's vital to ensure it is developed and used responsibly, with fairness, transparency, and accountability at its core.\n",
      "\n",
      "**What are your thoughts on the impact of AI? Share your perspectives in the comments below!** \n",
      "\n",
      "#AI #ArtificialIntelligence #FutureOfWork #Innovation #Ethics #Technology #LifelongLearning #HumanSkills #Discussion  \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tweet: \\n {result['tweet']}\")\n",
    "print(f\"Linkedin: \\n {result['linkedin']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runnable Passthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = PromptTemplate(\n",
    "    template='Write a joke about {topic}',\n",
    "    input_variables=['topic']\n",
    ")\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    template='Explain the following joke - {text}',\n",
    "    input_variables=['text']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "joke_gen_chain = RunnableSequence(prompt1, model, parser)\n",
    "\n",
    "parallel_chain = RunnableParallel({\n",
    "    'joke': RunnablePassthrough(),\n",
    "    'explanation': RunnableSequence(prompt2, model, parser)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = RunnableSequence(joke_gen_chain, parallel_chain)\n",
    "\n",
    "output=final_chain.invoke({'topic':'cricket'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke: \n",
      " Why did the cricket refuse to bowl? \n",
      "\n",
      "Because he was feeling a little out of his depth! üèè üòÇ  \n",
      "\n",
      "Explanation: \n",
      " This is a pun, playing on the double meaning of the phrase \"out of his depth.\"\n",
      "\n",
      "* **Literal meaning:** In cricket, a bowler delivers the ball. If a bowler is \"out of his depth,\" it means they are not skilled enough to bowl effectively in a particular situation, perhaps because the pitch is too difficult or the batsmen are too strong.\n",
      "\n",
      "* **Figurative meaning:**  \"Out of his depth\" also means to be in a situation that is too challenging or beyond one's capabilities.\n",
      "\n",
      "The joke combines these meanings, suggesting the cricket is literally feeling uncomfortable in the water (because crickets live on land) and metaphorically unable to handle the pressure of bowling.  \n",
      "\n",
      "\n",
      "Let me know if you'd like to hear another joke! üòä \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Joke: \\n {output['joke']}\")\n",
    "print(f\"Explanation: \\n {output['explanation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runnable Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(text):\n",
    "    return len(text.split())\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template='Write a joke about {topic}',\n",
    "    input_variables=['topic']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "joke_gen_chain = RunnableSequence(prompt, model, parser)\n",
    "\n",
    "parallel_chain = RunnableParallel({\n",
    "    'joke': RunnablePassthrough(),\n",
    "    'word_count': RunnableLambda(word_count)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke:\n",
      "Why did the AI cross the road? \n",
      "\n",
      "It was programmed to.  üêîü§ñ  \n",
      "\n",
      " \n",
      " word count - 12\n"
     ]
    }
   ],
   "source": [
    "final_chain = RunnableSequence(joke_gen_chain, parallel_chain)\n",
    "\n",
    "result = final_chain.invoke({'topic':'AI'})\n",
    "\n",
    "final_result = \"\"\"{} \\n word count - {}\"\"\".format(f\"Joke:\\n{result['joke']}\", result['word_count'])\n",
    "\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
